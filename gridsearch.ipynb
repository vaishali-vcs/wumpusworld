{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, random\n",
    "import numpy as np\n",
    "from tensorflow.keras.losses import MSE\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from statistics import mean\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "# use tf2\n",
    "# https://github.com/VXU1230/Medium-Tutorials/blob/master/dqn/cart_pole.py\n",
    "# https://towardsdatascience.com/deep-reinforcement-learning-build-a-deep-q-network-dqn-to-play-cartpole-with-tensorflow-2-and-gym-8e105744b998\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from wumpusworld.envs.WumpusGym import WumpusWorldEnv\n",
    "from BeelineAgent import Agent, Action\n",
    "\n",
    "WORLD_SIZE = 4\n",
    "\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, num_states, hidden_units, num_actions):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.input_layer = tf.keras.layers.InputLayer(input_shape=(num_states,))\n",
    "        self.hidden_layers = []\n",
    "        for i in hidden_units:\n",
    "            self.hidden_layers.append(tf.keras.layers.Dense(\n",
    "                i, activation='tanh', kernel_initializer='RandomNormal'))\n",
    "        self.output_layer = tf.keras.layers.Dense(\n",
    "            num_actions, activation='linear', kernel_initializer='RandomNormal')\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        z = self.input_layer(inputs)\n",
    "        for layer in self.hidden_layers:\n",
    "            z = layer(z)\n",
    "        output = self.output_layer(z)\n",
    "        return output\n",
    "\n",
    "\n",
    "class DQN:\n",
    "    def __init__(self, num_states, num_actions, hidden_units, gamma, max_experiences, min_experiences, batch_size, lr):\n",
    "        self.num_actions = num_actions\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = Adam(lr)\n",
    "        self.gamma = gamma\n",
    "        self.model = MyModel(num_states, hidden_units, num_actions)\n",
    "        self.experience = {'s': [], 'a': [], 'r': [], 's2': [], 'done': []}\n",
    "        self.max_experiences = max_experiences\n",
    "        self.min_experiences = min_experiences\n",
    "\n",
    "    def get_action(self, states, epsilon):\n",
    "        if np.random.random() < epsilon:\n",
    "            return np.random.choice(self.num_actions)\n",
    "        else:\n",
    "            return np.argmax(self.predict(np.atleast_2d(states))[0])\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        return self.model(np.atleast_2d(inputs.astype('float32')))\n",
    "\n",
    "    def add_experience(self, exp):\n",
    "        if len(self.experience['s']) >= self.max_experiences:\n",
    "            for key in self.experience.keys():\n",
    "                self.experience[key].pop(0)\n",
    "        for key, value in exp.items():\n",
    "            self.experience[key].append(value)\n",
    "        i = 1\n",
    "\n",
    "    def copy_weights(self, TrainNet):\n",
    "        variables1 = self.model.trainable_variables\n",
    "        variables2 = TrainNet.model.trainable_variables\n",
    "        for v1, v2 in zip(variables1, variables2):\n",
    "            v1.assign(v2.numpy())\n",
    "\n",
    "    def train(self, TargetNet, isdone):\n",
    "        if isdone:\n",
    "            pass\n",
    "        elif len(self.experience['s']) < self.min_experiences:\n",
    "            return 0\n",
    "\n",
    "        # ids = np.random.randint(low=0, high=len(self.experience['s']), size=self.batch_size)\n",
    "        ids = range(0, len(self.experience['s']))\n",
    "        states = np.asarray([self.experience['s'][i] for i in ids])\n",
    "        actions = np.asarray([self.experience['a'][i] for i in ids])\n",
    "        rewards = np.asarray([self.experience['r'][i] for i in ids])\n",
    "        states_next = np.asarray([self.experience['s2'][i] for i in ids])\n",
    "        dones = np.asarray([self.experience['done'][i] for i in ids])\n",
    "        value_next = np.max(TargetNet.predict(states_next), axis=-1)\n",
    "        actual_values = np.where(dones, rewards, rewards + self.gamma * value_next.squeeze())\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            selected_action_values = tf.math.reduce_sum(\n",
    "                self.predict(states) * tf.one_hot(actions, self.num_actions), axis=-1)\n",
    "            loss = tf.math.reduce_mean(tf.square(actual_values - selected_action_values))\n",
    "        variables = self.model.trainable_variables\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "        # if isinstance(loss, int):\n",
    "        #     print(loss)\n",
    "        # else:\n",
    "        #     print(loss.numpy())\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "l1 = 72\n",
    "l2 = 150\n",
    "l3 = 100\n",
    "l4 = 6\n",
    "\n",
    "loss_fn = MSE\n",
    "learning_rate = 1e-3\n",
    "optmizer = None\n",
    "\n",
    "\n",
    "def action_to_string(action):\n",
    "    \"\"\" action_to_string: return a string from the given action \"\"\"\n",
    "    if action == Action.WALK:\n",
    "        return \"WALK\"\n",
    "    if action == Action.TURNRIGHT:\n",
    "        return \"TURNRIGHT\"\n",
    "    if action == Action.TURNLEFT:\n",
    "        return \"TURNLEFT\"\n",
    "    if action == Action.SHOOT:\n",
    "        return \"SHOOT\"\n",
    "    if action == Action.GRAB:\n",
    "        return \"GRAB\"\n",
    "    if action == Action.CLIMB:\n",
    "        return \"CLIMB\"\n",
    "    return \"UNKNOWN ACTION\"\n",
    "\n",
    "\n",
    "def play_game(agent, env, TrainNet, TargetNet, epsilon, copy_step):\n",
    "    rewards = 0\n",
    "    iter = 0\n",
    "    done = False\n",
    "    observations = env.reset()\n",
    "    losses = list()\n",
    "    gameswon = 0\n",
    "    steps = 0\n",
    "    while not done:\n",
    "        state = agent.processPercepts(WORLD_SIZE, observations)\n",
    "        # print(state[0:16])\n",
    "        # print(state[16:32])\n",
    "        # print(state[32:48])\n",
    "        # print(state[48:64])\n",
    "        # print(state[64:])\n",
    "        action = TrainNet.get_action(state, epsilon)\n",
    "        steps += 1\n",
    "        # print(action_to_string(action))\n",
    "        prev_observations = state\n",
    "        observations, reward, done = env.step(action)\n",
    "\n",
    "        state2 = agent.processPercepts(WORLD_SIZE, observations)\n",
    "\n",
    "        rewards += int(reward)\n",
    "        if done:\n",
    "            env.reset()\n",
    "\n",
    "        exp = {'s': prev_observations, 'a': action, 'r': int(reward), 's2': state2, 'done': done}\n",
    "        TrainNet.add_experience(exp)\n",
    "\n",
    "    loss = TrainNet.train(TargetNet, done)\n",
    "    if isinstance(loss, int):\n",
    "        losses.append(loss)\n",
    "    else:\n",
    "        losses.append(loss.numpy())\n",
    "    iter += 1\n",
    "    if iter % copy_step == 0:\n",
    "        TargetNet.copy_weights(TrainNet)\n",
    "\n",
    "    if int(reward) > 0:\n",
    "        gameswon += 1\n",
    "\n",
    "    # print(\"steps=\", steps)\n",
    "    return rewards, mean(losses), gameswon, steps\n",
    "\n",
    "\n",
    "def playgame():\n",
    "    global res\n",
    "    sumgameswon = {}\n",
    "    for i, m in enumerate(models_arch):\n",
    "\n",
    "        env = WumpusWorldEnv()\n",
    "        # env.render()\n",
    "        agent = Agent()\n",
    "        gamma = 0.99\n",
    "        copy_step = 25\n",
    "        num_states = l1\n",
    "        num_actions = len(env.action_space)\n",
    "        hidden_units = m[\"dense_list\"]\n",
    "        max_experiences = m[\"MINIBATCH_SIZE\"]\n",
    "        min_experiences = m[\"MINIBATCH_SIZE\"]\n",
    "        batch_size = m[\"MINIBATCH_SIZE\"]\n",
    "        lr = 1e-2\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        model_name = m[\"modelname\"]\n",
    "        log_dir = 'logs/dqn/' + model_name + '/' + current_time\n",
    "        summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "        TrainNet = DQN(num_states, num_actions, hidden_units, gamma, max_experiences, min_experiences, batch_size, lr)\n",
    "        TargetNet = DQN(num_states, num_actions, hidden_units, gamma, max_experiences, min_experiences, batch_size, lr)\n",
    "        N = 5000\n",
    "        total_rewards = np.empty(N)\n",
    "        epsilon = 0.99\n",
    "        decay = 0.9999\n",
    "        min_epsilon = 0.1\n",
    "        sumgameswon[i] = 0\n",
    "      \n",
    "        for n in tqdm(range(N)):\n",
    "           \n",
    "            epsilon = max(min_epsilon, epsilon * decay)\n",
    "            total_reward, losses, gameswon, stepstaken = play_game(agent, env, TrainNet, TargetNet, epsilon, copy_step)\n",
    "            sumgameswon[i] += gameswon\n",
    "            total_rewards[n] = total_reward\n",
    "            avg_rewards = total_rewards[max(0, n - 100):(n + 1)].mean()\n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar('episode reward', total_reward, step=n)\n",
    "                tf.summary.scalar('running avg reward(100)', avg_rewards, step=n)\n",
    "                tf.summary.scalar('average loss)', losses, step=n)\n",
    "                tf.summary.scalar('stepstaken)', stepstaken, step=n)\n",
    "                tf.summary.scalar('gameswon)', gameswon, step=n)\n",
    "\n",
    "\n",
    "        res = res.append(\n",
    "            {\"Model Name\": model_name, \"Dense Layers\": m[\"dense_list\"],\n",
    "             \"Batch Size\": m[\"MINIBATCH_SIZE\"], \"Total games won\": sumgameswon[i]}\n",
    "            , ignore_index=True)\n",
    "\n",
    "        # print(\"gameswon= by model = \", sumgameswon[i], model_name)\n",
    "\n",
    "\n",
    "models_arch = [{\"modelname\": 'M150_100', \"dense_list\": [150, 100], \"MINIBATCH_SIZE\": 32},\n",
    "               {\"modelname\": 'M150_100', \"dense_list\": [150, 100], \"MINIBATCH_SIZE\": 64},\n",
    "               {\"modelname\": 'M150_100', \"dense_list\": [150, 100], \"MINIBATCH_SIZE\": 128},\n",
    "\n",
    "               {\"modelname\": 'M150_100', \"dense_list\": [200, 200], \"MINIBATCH_SIZE\": 32},\n",
    "               {\"modelname\": 'M150_100', \"dense_list\": [200, 200], \"MINIBATCH_SIZE\": 64},\n",
    "               {\"modelname\": 'M150_100', \"dense_list\": [200, 200], \"MINIBATCH_SIZE\": 128},\n",
    "\n",
    "               {\"modelname\": 'M128_100_64', \"dense_list\": [128, 100, 64], \"MINIBATCH_SIZE\": 32},\n",
    "               {\"modelname\": 'M128_100_64', \"dense_list\": [128, 100, 64], \"MINIBATCH_SIZE\": 64},\n",
    "               {\"modelname\": 'M128_100_64', \"dense_list\": [128, 100, 64], \"MINIBATCH_SIZE\": 128},\n",
    "\n",
    "               {\"modelname\": 'M64_32', \"dense_list\": [64, 32], \"MINIBATCH_SIZE\": 32},\n",
    "               {\"modelname\": 'M64_32', \"dense_list\": [64, 32], \"MINIBATCH_SIZE\": 64},\n",
    "               {\"modelname\": 'M64_32', \"dense_list\": [64, 32], \"MINIBATCH_SIZE\": 128}]\n",
    "\n",
    "# A dataframe used to store grid search results\n",
    "res = pd.DataFrame(columns=[\"Model Name\", \"Dense Layers\", \"Batch Size\",\n",
    "                            \"Total games won\"\n",
    "                            ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [05:48<00:00, 14.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [04:46<00:00, 17.45it/s]\n",
      "  0%|                                                                                 | 3/5000 [00:00<15:43,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function MyModel.call at 0x0000014CC6AFC828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                 | 4/5000 [00:00<14:45,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function MyModel.call at 0x0000014F2380AC18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function MyModel.call at 0x0000014CC6AFC828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                 | 5/5000 [00:00<12:56,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function MyModel.call at 0x0000014F2380AC18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function MyModel.call at 0x0000014CC6AFC828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [05:45<00:00, 14.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [06:18<00:00, 13.21it/s]\n",
      "  0%|                                                                                 | 3/5000 [00:00<13:00,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function MyModel.call at 0x0000014CBFF83B88> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [05:09<00:00, 16.14it/s]\n",
      "  0%|                                                                                 | 2/5000 [00:00<16:01,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function MyModel.call at 0x0000014F24A98828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                 | 4/5000 [00:00<13:29,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function MyModel.call at 0x0000014CBFF7C798> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function MyModel.call at 0x0000014F24A98828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [05:12<00:00, 15.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [08:44<00:00,  9.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [05:07<00:00, 16.25it/s]\n",
      "  0%|                                                                                 | 3/5000 [00:00<15:09,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function MyModel.call at 0x0000014CBD6C7168> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                 | 4/5000 [00:00<13:28,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function MyModel.call at 0x0000014CBFF820D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 8 calls to <function MyModel.call at 0x0000014CBD6C7168> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [05:13<00:00, 15.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [06:17<00:00, 13.24it/s]\n",
      "  0%|                                                                                 | 3/5000 [00:00<12:52,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function MyModel.call at 0x0000014CBFF83EE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function MyModel.call at 0x0000014CBFF7C0D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function MyModel.call at 0x0000014CBFF83EE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                 | 5/5000 [00:00<11:12,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function MyModel.call at 0x0000014CBFF7C0D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 8 calls to <function MyModel.call at 0x0000014CBFF83EE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [04:39<00:00, 17.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [05:07<00:00, 16.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Grid Search:\n",
    "playgame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dense Layers</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Total games won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M150_100</td>\n",
       "      <td>[150, 100]</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M150_100</td>\n",
       "      <td>[150, 100]</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M150_100</td>\n",
       "      <td>[150, 100]</td>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M150_100</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>32</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M150_100</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M150_100</td>\n",
       "      <td>[200, 200]</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M128_100_64</td>\n",
       "      <td>[128, 100, 64]</td>\n",
       "      <td>32</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M128_100_64</td>\n",
       "      <td>[128, 100, 64]</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M128_100_64</td>\n",
       "      <td>[128, 100, 64]</td>\n",
       "      <td>128</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M64_32</td>\n",
       "      <td>[64, 32]</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M64_32</td>\n",
       "      <td>[64, 32]</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M64_32</td>\n",
       "      <td>[64, 32]</td>\n",
       "      <td>128</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model Name    Dense Layers Batch Size Total games won\n",
       "0      M150_100      [150, 100]         32               6\n",
       "1      M150_100      [150, 100]         64               0\n",
       "2      M150_100      [150, 100]        128               7\n",
       "3      M150_100      [200, 200]         32             353\n",
       "4      M150_100      [200, 200]         64              14\n",
       "5      M150_100      [200, 200]        128               2\n",
       "6   M128_100_64  [128, 100, 64]         32             315\n",
       "7   M128_100_64  [128, 100, 64]         64               1\n",
       "8   M128_100_64  [128, 100, 64]        128              23\n",
       "9        M64_32        [64, 32]         32              29\n",
       "10       M64_32        [64, 32]         64               7\n",
       "11       M64_32        [64, 32]        128              22"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
